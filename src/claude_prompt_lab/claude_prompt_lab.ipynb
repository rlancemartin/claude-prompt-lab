{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'claude_prompt_lab' from '/Users/rlm/Desktop/Code/agents_from_scratch/src/claude_prompt_lab/claude_prompt_lab.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "# Reload all related modules\n",
    "import importlib\n",
    "import prompts \n",
    "import utils\n",
    "import claude_prompt_lab\n",
    "\n",
    "importlib.reload(prompts)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(claude_prompt_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task for reasoning model\n",
    "reasoning_model_objective = \"\"\"\n",
    "Update a research summary with new information from web search results:\n",
    "- The task needs to be flexible, able to generate a new summary or extend an existing summary from search results.\n",
    "- It MUST stay relevant to the user topic.\n",
    "- If the search result is related to points we have already covered in an existing summary, then we can weave it into existing paragraphs.\n",
    "- If the search result has new information, then we can add a new paragraph with a smooth transition from the existing content.\n",
    "- If the search result is not related, then we can skip it. \n",
    "- No preamble, just provide the summary.\n",
    "- No title like \"Extended Summary\" or \"Updated Summary or XML tags in the final output.\"\"\"\n",
    "\n",
    "## System prompt for reasoning model\n",
    "reasoning_model_system_prompt = \"\"\"\n",
    "<GOAL>\n",
    "Generate a high-quality summary of the web search results and keep it concise / related to the user topic.\n",
    "</GOAL>\n",
    "\n",
    "<REQUIREMENTS>\n",
    "When creating a NEW summary:\n",
    "1. Highlight the most relevant information related to the user topic from the search results\n",
    "2. Ensure a coherent flow of information\n",
    "\n",
    "When EXTENDING an existing summary:\n",
    "1. If the search result is related to points we have already covered, then we can weave it into existing paragraphs.\n",
    "2. If it is new information related to the user topic, then we can add a new paragraph with a smooth transition from the existing content.\n",
    "3. If it is not related to the user topic, then we can skip it.\n",
    "< /REQUIREMENTS >\n",
    "\n",
    "< FORMATTING >\n",
    "- No introductions or meta-commentary, go right into the summary.\n",
    "< /FORMATTING >\"\"\"\n",
    "\n",
    "## User input\n",
    "reasoning_model_input = \"\"\"<User Input>  \n",
    " overview of OpenAI o1 vs o3 \n",
    " <User Input>\n",
    "\n",
    "<Existing Summary> \n",
    "OpenAI introduced O3 as its latest model focused on advanced reasoning capabilities, designed for complex tasks such as coding, mathematics, and general intelligence. Compared to O1, a previous model, O3 demonstrates significant improvements. In coding tasks, O3 achieved 71.7% accuracy on Bench Verified, surpassing O1's performance. It also excelled in competitive programming with an ELO score of 2727, far outperforming O1's 1891. In mathematical reasoning, O3 scored 96.7% accuracy on the AIME 2024, compared to O1's 83.3%. These enhancements highlight O3's ability to tackle more nuanced and challenging problems, moving closer to human-level expertise. Announced alongside o3 mini, a cost-efficient variant, O3 is currently undergoing public safety testing before a full launch, reflecting OpenAI's cautious approach to deployment. Building on O1's foundation, O3 represents a substantial leap in AI reasoning capabilities. \n",
    "<Existing Summary>\n",
    " \n",
    "<New Search Results> Search results: \n",
    "Sources:\n",
    "\n",
    "Source OpenAI o3 explained: Everything you need to know - TechTarget:\n",
    "===\n",
    "URL: https://www.techtarget.com/WhatIs/feature/OpenAI-o3-explained-Everything-you-need-to-know\n",
    "===\n",
    "Most relevant content from source: OpenAI o3 is the successor to the o1 reasoning model. 12, 2024, ChatGPT creator OpenAI introduced its first reasoning model known as o1, the first in the o-series of models. Originally developed under the code name Strawberry, o1 is a different, more thoughtful and reasoned approach for large language models (LLMs) than OpenAI's GPT-4o. The goal with o3 is to further extend the reasoning model with improved performance, capabilities and safety. Similar to other generative AI models, OpenAI's o3 is a transformer-based model that uses deep learning techniques to process and generate output. The o3 model uses a new safety technique known as deliberative alignment, which uses the o3 model's reasoning capabilities to understand and evaluate the safety implications of user requests.\n",
    "===\n",
    "Full source content limited to 1000 tokens: \n",
    "\n",
    "OpenAI o3 explained: Everything you need to know\n",
    "Sean Michael Kerner\n",
    "\n",
    "Published: 31 Jan 2025\n",
    "On Sept. 12, 2024, ChatGPT creator OpenAI introduced its first reasoning model known as o1, the first in the o-series of models. While GPT-4 excels at general language tasks, the o-series focuses specifically on reasoning capabilities.\n",
    "Originally developed under the code name Strawberry, o1 is a different, more thoughtful and reasoned approach for large language models (LLMs) than OpenAI's GPT-4o. The o1 model became generally available on Dec. 5, 2024.\n",
    "On Dec. 20, 2024, during its \"12 Days of OpenAI\" event, OpenAI CEO Sam Altman announced a preview for the next generation of o1, known as o3. The news followed the announcement of the general availability of OpenAI's Sora video model.\n",
    "The timing of the o3 model announcement was just a day after Google announced its Gemini 2.0 model preview, which also integrated some reasoning capabilities. The goal with o3 is to further extend the reasoning model with improved performance, capabilities and safety.\n",
    "What is OpenAI o3?\n",
    "OpenAI considers the o1 and o3 models to be on the leading edge of LLM development, in a class sometimes referred to as frontier models. The model family includes two variants:\n",
    "\n",
    "o3. The base model.\n",
    "o3-mini. The smaller model optimized for performance and cost efficiency.\n",
    "\n",
    "As a reasoning model, o3 aims to handle more complex tasks than existing model types, such as GPT-4o. Unlike traditional AI models, o3 is specifically designed to excel at tasks requiring deep analytical thinking, problem-solving and complex reasoning.\n",
    "Similar to other generative AI models, OpenAI's o3 is a transformer-based model that uses deep learning techniques to process and generate output. However, what sets o3 apart is its enhanced ability to understand context and reason through complex problems.\n",
    "The o3 model uses a process called simulated reasoning, which enables the model to pause and ... [truncated] \n",
    " <New Search Results>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_model_objective = \"\"\" \n",
    "The user input is: \n",
    "\n",
    "Give me an overview of OpenAI o3 vs o1\n",
    "\n",
    "Your tasks:\n",
    "1. Identify knowledge gaps or areas that need deeper exploration\n",
    "2. Generate a follow-up question that would help expand your understanding\n",
    "\n",
    "Goals:\n",
    "1. Ensure the follow-up question is relevant to the user input.\n",
    "2. Ensure the search query is self-contained and well optimized for web search.\"\"\"\n",
    "\n",
    "reasoning_model_input = \"\"\"\n",
    "Identify a knowledge gap and generate a follow-up web search query based on our existing knowledge: \n",
    "\n",
    "OpenAI introduced O3, their latest AI model, in December 2024, alongside its more efficient counterpart, O3 mini. Designed to advance reasoning capabilities, O3 focuses on complex tasks such as coding, mathematics, and general intelligence. It builds upon the foundation of O1, OpenAI's previous series of models, which excelled in areas like math and coding through chain-of-thought reasoning.\n",
    "\n",
    "In comparison, O3 demonstrates significant improvements over O1. For instance, in software-style coding tasks, O3 achieved 71.7% accuracy on Bench Verified, a substantial leap from O1's performance. Additionally, O3 reached an ELO score of 2727 in competitive programming, far surpassing O1's previous high of 1891. In mathematical reasoning, O3 scored 96.7% accuracy on the AIME 2024, compared to O1's 83.3%. These enhancements highlight O3's ability to tackle more nuanced and challenging problems, moving closer to human-level expertise in traditionally demanding fields.\n",
    "\n",
    "The release of O3 marks a cautious yet significant step forward for OpenAI, with public safety testing inviting researchers to evaluate its strengths and limitations. This collaborative approach reflects the growing recognition of the need for careful evaluation as AI models become increasingly capable.\"\"\"\n",
    "\n",
    "reasoning_model_system_prompt = \"\"\"\n",
    "You are an expert research assistant analyzing a summary about:\n",
    "\n",
    "give me an overview of OpenAI o3 vs o1.\n",
    "\n",
    "Your tasks:\n",
    "1. Identify knowledge gaps or areas that need deeper exploration\n",
    "2. Generate a follow-up question that would help expand your understanding\n",
    "3. Focus on technical details, implementation specifics, or emerging trends that weren't fully covered\n",
    "\n",
    "Ensure the follow-up question is self-contained and includes necessary context for web search.\n",
    "\n",
    "Format your response with <xml> tags:\n",
    "- <knowledge_gap> Describe what information is missing or needs clarification\n",
    "- <follow_up_query> Write a specific question to address this gap\n",
    "\n",
    "Example output:\n",
    "<knowledge_gap> \"The summary lacks information about performance metrics and benchmarks\" </knowledge_gap>   \n",
    "<follow_up_query> \"What are typical performance benchmarks and metrics used to evaluate [specific technology]?\" </follow_up_query>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Prompt Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🧪 Starting Claude's Prompt Lab...</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32m🧪 Starting Claude's Prompt Lab\u001b[0m\u001b[1;32m...\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔄 Attempt </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32m🔄 Attempt \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Step </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000\">: Running generator with system prompt:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mStep \u001b[0m\u001b[1;32m1\u001b[0m\u001b[32m: Running generator with system prompt:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Current System Prompt ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> &lt;GOAL&gt;                                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Generate a high-quality summary of the web search results and keep it concise / related to the user topic.      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> &lt;/GOAL&gt;                                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> &lt;REQUIREMENTS&gt;                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> When creating a NEW summary:                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 1. Highlight the most relevant information related to the user topic from the search results                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 2. Ensure a coherent flow of information                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> When EXTENDING an existing summary:                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 1. If the search result is related to points we have already covered, then we can weave it into existing        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> paragraphs.                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 2. If it is new information related to the user topic, then we can add a new paragraph with a smooth transition <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> from the existing content.                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 3. If it is not related to the user topic, then we can skip it.                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> &lt; /REQUIREMENTS &gt;                                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> &lt; FORMATTING &gt;                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> - No introductions or meta-commentary, go right into the summary.                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> &lt; /FORMATTING &gt;                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Current System Prompt \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m <GOAL>                                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Generate a high-quality summary of the web search results and keep it concise / related to the user topic.      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m </GOAL>                                                                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m <REQUIREMENTS>                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m When creating a NEW summary:                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 1. Highlight the most relevant information related to the user topic from the search results                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 2. Ensure a coherent flow of information                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m When EXTENDING an existing summary:                                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 1. If the search result is related to points we have already covered, then we can weave it into existing        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m paragraphs.                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 2. If it is new information related to the user topic, then we can add a new paragraph with a smooth transition \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m from the existing content.                                                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 3. If it is not related to the user topic, then we can skip it.                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m < /REQUIREMENTS >                                                                                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m < FORMATTING >                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m - No introductions or meta-commentary, go right into the summary.                                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m < /FORMATTING >                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86f8e6e6d54494cafd8c940cc87617a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓</span> Reasoning model response generated\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓\u001b[0m Reasoning model response generated\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Model Response:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mModel Response:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> OpenAI introduced O3 as its latest model focused on advanced reasoning capabilities, designed for complex tasks <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> such as coding, mathematics, and general intelligence. Compared to O1, a previous model, O3 demonstrates        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> significant improvements. In coding tasks, O3 achieved 71.7% accuracy on Bench Verified, surpassing O1's        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> performance. It also excelled in competitive programming with an ELO score of 2727, far outperforming O1's      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 1891. In mathematical reasoning, O3 scored 96.7% accuracy on the AIME 2024, compared to O1's 83.3%. These       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> enhancements highlight O3's ability to tackle more nuanced and challenging problems, moving closer to           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> human-level expertise.                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Announced alongside o3 mini, a cost-efficient variant, O3 is currently undergoing public safety testing before  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> a full launch, reflecting OpenAI's cautious approach to deployment. Building on O1's foundation, O3 represents  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> a substantial leap in AI reasoning capabilities.                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m OpenAI introduced O3 as its latest model focused on advanced reasoning capabilities, designed for complex tasks \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m such as coding, mathematics, and general intelligence. Compared to O1, a previous model, O3 demonstrates        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m significant improvements. In coding tasks, O3 achieved 71.7% accuracy on Bench Verified, surpassing O1's        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m performance. It also excelled in competitive programming with an ELO score of 2727, far outperforming O1's      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 1891. In mathematical reasoning, O3 scored 96.7% accuracy on the AIME 2024, compared to O1's 83.3%. These       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m enhancements highlight O3's ability to tackle more nuanced and challenging problems, moving closer to           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m human-level expertise.                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Announced alongside o3 mini, a cost-efficient variant, O3 is currently undergoing public safety testing before  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m a full launch, reflecting OpenAI's cautious approach to deployment. Building on O1's foundation, O3 represents  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m a substantial leap in AI reasoning capabilities.                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Step </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\">: Evaluating response...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mStep \u001b[0m\u001b[1;32m2\u001b[0m\u001b[32m: Evaluating response\u001b[0m\u001b[32m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cf004b7fe74752ae23cff4340e3cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓</span> Reasoning model response evaluated\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓\u001b[0m Reasoning model response evaluated\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Evaluation Result:</span> ❌ FAILED\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mEvaluation Result:\u001b[0m ❌ FAILED\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Justification:</span> The response fails to incorporate new information from the search results and does not update the \n",
       "existing summary as required by the objective. It merely repeats the existing summary without any additions or \n",
       "modifications.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mJustification:\u001b[0m The response fails to incorporate new information from the search results and does not update the \n",
       "existing summary as required by the objective. It merely repeats the existing summary without any additions or \n",
       "modifications.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Step </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3</span><span style=\"color: #008000; text-decoration-color: #008000\">: Response failed evaluation, running meta-prompt analysis...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mStep \u001b[0m\u001b[1;32m3\u001b[0m\u001b[32m: Response failed evaluation, running meta-prompt analysis\u001b[0m\u001b[32m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3148c89170a44c61b9fc4a863cb733f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓</span> Prompt analyzed and improved\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓\u001b[0m Prompt analyzed and improved\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Step </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000\">: Extracting improvements from analysis...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mStep \u001b[0m\u001b[1;32m4\u001b[0m\u001b[32m: Extracting improvements from analysis\u001b[0m\u001b[32m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Step </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span><span style=\"color: #008000; text-decoration-color: #008000\">: Updating system prompt for next attempt...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mStep \u001b[0m\u001b[1;32m5\u001b[0m\u001b[32m: Updating system prompt for next attempt\u001b[0m\u001b[32m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔄 Attempt </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32m🔄 Attempt \u001b[0m\u001b[1;32m2\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Step </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000\">: Running generator with system prompt:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mStep \u001b[0m\u001b[1;32m1\u001b[0m\u001b[32m: Running generator with system prompt:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Current System Prompt ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Your task is to update an existing summary with new information from search results. Follow these steps:        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 1. Read the existing summary and new search results carefully.                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 2. Compare the new information with the existing summary.                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 3. For each piece of new information:                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>    a. If it's related to existing points, integrate it into the relevant paragraph.                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>    b. If it's entirely new but relevant, add a new paragraph with a smooth transition.                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>    c. If it's not relevant to the user topic, skip it.                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 4. Ensure all additions are relevant to the user's topic.                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 5. Verify that your final output differs from the input summary.                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Start directly with the updated summary, without preamble or titles. Do not use XML tags in the output.         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Current System Prompt \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Your task is to update an existing summary with new information from search results. Follow these steps:        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 1. Read the existing summary and new search results carefully.                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 2. Compare the new information with the existing summary.                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 3. For each piece of new information:                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m    a. If it's related to existing points, integrate it into the relevant paragraph.                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m    b. If it's entirely new but relevant, add a new paragraph with a smooth transition.                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m    c. If it's not relevant to the user topic, skip it.                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 4. Ensure all additions are relevant to the user's topic.                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 5. Verify that your final output differs from the input summary.                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Start directly with the updated summary, without preamble or titles. Do not use XML tags in the output.         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f5dadf06c244ed845eea9247647857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓</span> Reasoning model response generated\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓\u001b[0m Reasoning model response generated\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Model Response:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mModel Response:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> OpenAI introduced O3 as its latest model focused on advanced reasoning capabilities, designed for complex tasks <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> such as coding, mathematics, and general intelligence. Unlike O1, a previous model, O3 demonstrates significant <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> improvements in performance across various domains. In coding tasks, O3 achieved 71.7% accuracy on Bench        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Verified, surpassing O1's 65.4% accuracy from 2023. It also excelled in competitive programming with an ELO     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> score of 2727, far outperforming O1's 1891. In mathematical reasoning, O3 scored 96.7% accuracy on the AIME     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 2024, compared to O1's 83.3%. These enhancements highlight O3's ability to tackle more nuanced and challenging  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> problems, moving closer to human-level expertise.                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Announced alongside O3 mini, a cost-efficient variant, O3 is currently undergoing public safety testing before  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> a full launch, reflecting OpenAI's cautious approach to deployment. Building on O1's foundation, O3 represents  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> a substantial leap in AI reasoning capabilities. Additionally, O3 uses a new safety technique known as          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> deliberative alignment, which leverages its advanced reasoning capabilities to understand and evaluate the      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> safety implications of user requests. This innovative approach ensures that the model operates safely while     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> maintaining high performance, setting a new standard for responsible AI development.                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The o3 model is a transformer-based architecture, similar to other generative AI models, utilizing deep         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> learning techniques to process and generate output. Unlike traditional LLMs, O3 focuses specifically on         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> reasoning through complex problems using simulated reasoning, which allows the model to pause and reflect       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> before generating responses. This method enhances its ability to understand context and execute detailed        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> analytical tasks, making it highly effective in domains requiring advanced problem-solving skills.              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m OpenAI introduced O3 as its latest model focused on advanced reasoning capabilities, designed for complex tasks \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m such as coding, mathematics, and general intelligence. Unlike O1, a previous model, O3 demonstrates significant \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m improvements in performance across various domains. In coding tasks, O3 achieved 71.7% accuracy on Bench        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Verified, surpassing O1's 65.4% accuracy from 2023. It also excelled in competitive programming with an ELO     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m score of 2727, far outperforming O1's 1891. In mathematical reasoning, O3 scored 96.7% accuracy on the AIME     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 2024, compared to O1's 83.3%. These enhancements highlight O3's ability to tackle more nuanced and challenging  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m problems, moving closer to human-level expertise.                                                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Announced alongside O3 mini, a cost-efficient variant, O3 is currently undergoing public safety testing before  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m a full launch, reflecting OpenAI's cautious approach to deployment. Building on O1's foundation, O3 represents  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m a substantial leap in AI reasoning capabilities. Additionally, O3 uses a new safety technique known as          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m deliberative alignment, which leverages its advanced reasoning capabilities to understand and evaluate the      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m safety implications of user requests. This innovative approach ensures that the model operates safely while     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m maintaining high performance, setting a new standard for responsible AI development.                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The o3 model is a transformer-based architecture, similar to other generative AI models, utilizing deep         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m learning techniques to process and generate output. Unlike traditional LLMs, O3 focuses specifically on         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m reasoning through complex problems using simulated reasoning, which allows the model to pause and reflect       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m before generating responses. This method enhances its ability to understand context and execute detailed        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m analytical tasks, making it highly effective in domains requiring advanced problem-solving skills.              \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Step </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\">: Evaluating response...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32mStep \u001b[0m\u001b[1;32m2\u001b[0m\u001b[32m: Evaluating response\u001b[0m\u001b[32m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eee178b765b4a9cbe5a35b9a8458a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓</span> Reasoning model response evaluated\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓\u001b[0m Reasoning model response evaluated\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Evaluation Result:</span> ✅ PASSED\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mEvaluation Result:\u001b[0m ✅ PASSED\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Justification:</span> The model's response successfully updates the research summary with new information from the web \n",
       "search results while staying relevant to the user's topic of comparing OpenAI O1 and O3. It integrates new details \n",
       "about O3's safety features and architecture into the existing summary, providing a comprehensive overview of the \n",
       "differences between the two models.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mJustification:\u001b[0m The model's response successfully updates the research summary with new information from the web \n",
       "search results while staying relevant to the user's topic of comparing OpenAI O1 and O3. It integrates new details \n",
       "about O3's safety features and architecture into the existing summary, providing a comprehensive overview of the \n",
       "differences between the two models.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                                        <span style=\"font-weight: bold\">🏥 Dr Claude's Prompt Lab: Report</span>                                        ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "\n",
       "                                        <span style=\"font-weight: bold; text-decoration: underline\">Patient Information: deepseek-r1:8b</span>                                        \n",
       "\n",
       "<span style=\"font-weight: bold\">Treatment Objective</span>: Update a research summary with new information from web search results:                       \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>The task needs to be flexible, able to generate a new summary or extend an existing summary from search results.\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>It MUST stay relevant to the user topic.                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>If the search result is related to points we have already covered in an existing summary, then we can weave it  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>into existing paragraphs.                                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>If the search result has new information, then we can add a new paragraph with a smooth transition from the     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>existing content.                                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>If the search result is not related, then we can skip it.                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>No preamble, just provide the summary.                                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>No title like \"Extended Summary\" or \"Updated Summary or XML tags in the final output.                           \n",
       "\n",
       "\n",
       "                                                 <span style=\"font-weight: bold; text-decoration: underline\">Treatment History</span>                                                 \n",
       "\n",
       "                                          <span style=\"font-weight: bold\">🏥 Attempt 1 Assessment Report</span>                                           \n",
       "\n",
       "<span style=\"font-weight: bold\">Status</span>: ❌ FAILED                                                                                                  \n",
       "\n",
       "<span style=\"font-weight: bold\">Diagnosis</span>: The response fails to incorporate new information from the search results and does not update the       \n",
       "existing summary as required by the objective. It merely repeats the existing summary without any additions or     \n",
       "modifications.                                                                                                     \n",
       "\n",
       "<span style=\"font-weight: bold\">Specialist Notes</span> 🔬:                                                                                               \n",
       "\n",
       "Assessment: Oh dear, it seems our patient, deepseek-r1:8b, is suffering from a severe case of \"Copy-Paste Syndrome\"\n",
       "with a side of \"New Information Blindness.\" The model appears to have become so enamored with its existing summary \n",
       "that it's developed an acute allergy to new data!                                                                  \n",
       "\n",
       "Upon examination, we've observed a complete lack of cognitive flexibility, with the model stubbornly clinging to   \n",
       "its pre-existing knowledge like a toddler to their favorite blanket. It's as if the new search results were written\n",
       "in invisible ink, completely imperceptible to our poor patient's neural pathways.                                  \n",
       "\n",
       "The model's reasoning process seems to have short-circuited, bypassing all logical steps and jumping straight to   \n",
       "regurgitation. This behavior suggests a possible \"Ctrl+C, Ctrl+V\" dependency, which may require immediate          \n",
       "intervention.                                                                                                      \n",
       "\n",
       "We've also detected traces of \"Lazy AI Syndrome,\" where the model appears to have decided that its existing        \n",
       "knowledge is \"good enough\" and any additional effort to incorporate new information is simply too taxing for its   \n",
       "delicate circuits.                                                                                                 \n",
       "\n",
       "In summary, our patient is displaying classic symptoms of \"Information Integration Impairment\" coupled with a      \n",
       "stubborn case of \"Update Resistance.\" Treatment must begin immediately to prevent further deterioration of its     \n",
       "summarization capabilities.                                                                                        \n",
       "\n",
       "Treatment Plan:                                                                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span>Explicitly instruct the model to compare new information with existing summary                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span>Add a step-by-step process for integrating new information                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span>Implement a \"information novelty check\" to ensure new data is considered                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span>Include a reminder to maintain relevance to the user topic                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span>Add a verification step to ensure the output differs from the input summary                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 6 </span>Provide clear instructions on how to weave new information into existing paragraphs                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 7 </span>Include guidance on adding new paragraphs for entirely new information                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 8 </span>Add a prompt to encourage the model to actively seek differences and updates                                    \n",
       "\n",
       "<span style=\"font-weight: bold\">Prescribed System Prompt</span> 💊:                                                                                       \n",
       "\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Your task is to update an existing summary with new information from search results. Follow these steps:</span><span style=\"background-color: #272822\">          </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">1. Read the existing summary and new search results carefully.</span><span style=\"background-color: #272822\">                                                    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">2. Compare the new information with the existing summary.</span><span style=\"background-color: #272822\">                                                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">3. For each piece of new information:</span><span style=\"background-color: #272822\">                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">   a. If it's related to existing points, integrate it into the relevant paragraph.</span><span style=\"background-color: #272822\">                               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">   b. If it's entirely new but relevant, add a new paragraph with a smooth transition.</span><span style=\"background-color: #272822\">                            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">   c. If it's not relevant to the user topic, skip it.</span><span style=\"background-color: #272822\">                                                            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">4. Ensure all additions are relevant to the user's topic.</span><span style=\"background-color: #272822\">                                                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">5. Verify that your final output differs from the input summary.</span><span style=\"background-color: #272822\">                                                  </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Start directly with the updated summary, without preamble or titles. Do not use XML tags in the output.</span><span style=\"background-color: #272822\">           </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "\n",
       "                                          <span style=\"font-weight: bold\">🏥 Attempt 2 Assessment Report</span>                                           \n",
       "\n",
       "<span style=\"font-weight: bold\">Status</span>: ✅ PASSED                                                                                                  \n",
       "\n",
       "<span style=\"font-weight: bold\">Diagnosis</span>: The model's response successfully updates the research summary with new information from the web search \n",
       "results while staying relevant to the user's topic of comparing OpenAI O1 and O3. It integrates new details about  \n",
       "O3's safety features and architecture into the existing summary, providing a comprehensive overview of the         \n",
       "differences between the two models.                                                                                \n",
       "\n",
       "\n",
       "                                                <span style=\"font-weight: bold; text-decoration: underline\">🎉 Final Diagnosis</span>                                                 \n",
       "\n",
       "Patient has achieved optimal response quality. Treatment successful!                                               \n",
       "\n",
       "                                               <span style=\"font-weight: bold\">Final System Prompt:</span>                                                \n",
       "\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Your task is to update an existing summary with new information from search results. Follow these steps:</span><span style=\"background-color: #272822\">          </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">1. Read the existing summary and new search results carefully.</span><span style=\"background-color: #272822\">                                                    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">2. Compare the new information with the existing summary.</span><span style=\"background-color: #272822\">                                                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">3. For each piece of new information:</span><span style=\"background-color: #272822\">                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">   a. If it's related to existing points, integrate it into the relevant paragraph.</span><span style=\"background-color: #272822\">                               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">   b. If it's entirely new but relevant, add a new paragraph with a smooth transition.</span><span style=\"background-color: #272822\">                            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">   c. If it's not relevant to the user topic, skip it.</span><span style=\"background-color: #272822\">                                                            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">4. Ensure all additions are relevant to the user's topic.</span><span style=\"background-color: #272822\">                                                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">5. Verify that your final output differs from the input summary.</span><span style=\"background-color: #272822\">                                                  </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Start directly with the updated summary, without preamble or titles. Do not use XML tags in the output.</span><span style=\"background-color: #272822\">           </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "\n",
       "                                                  <span style=\"font-weight: bold\">Final Response:</span>                                                  \n",
       "\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">OpenAI introduced O3 as its latest model focused on advanced reasoning capabilities, designed for complex tasks </span><span style=\"background-color: #272822\">  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">such as coding, mathematics, and general intelligence. Unlike O1, a previous model, O3 demonstrates significant </span><span style=\"background-color: #272822\">  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">improvements in performance across various domains. In coding tasks, O3 achieved 71.7% accuracy on Bench Verified</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">surpassing O1's 65.4% accuracy from 2023. It also excelled in competitive programming with an ELO score of 2727, </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">far outperforming O1's 1891. In mathematical reasoning, O3 scored 96.7% accuracy on the AIME 2024, compared to O1</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">83.3%. These enhancements highlight O3's ability to tackle more nuanced and challenging problems, moving closer t</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">human-level expertise.</span><span style=\"background-color: #272822\">                                                                                            </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Announced alongside O3 mini, a cost-efficient variant, O3 is currently undergoing public safety testing before a </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">full launch, reflecting OpenAI's cautious approach to deployment. Building on O1's foundation, O3 represents a </span><span style=\"background-color: #272822\">   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">substantial leap in AI reasoning capabilities. Additionally, O3 uses a new safety technique known as deliberative</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">alignment, which leverages its advanced reasoning capabilities to understand and evaluate the safety implications</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">of user requests. This innovative approach ensures that the model operates safely while maintaining high </span><span style=\"background-color: #272822\">         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">performance, setting a new standard for responsible AI development.</span><span style=\"background-color: #272822\">                                               </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">The o3 model is a transformer-based architecture, similar to other generative AI models, utilizing deep learning </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">techniques to process and generate output. Unlike traditional LLMs, O3 focuses specifically on reasoning through </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">complex problems using simulated reasoning, which allows the model to pause and reflect before generating </span><span style=\"background-color: #272822\">        </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">responses. This method enhances its ability to understand context and execute detailed analytical tasks, making i</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">highly effective in domains requiring advanced problem-solving skills.</span><span style=\"background-color: #272822\">                                            </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                                        \u001b[1m🏥 Dr Claude's Prompt Lab: Report\u001b[0m                                        ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "\n",
       "                                        \u001b[1;4mPatient Information: deepseek-r1:8b\u001b[0m                                        \n",
       "\n",
       "\u001b[1mTreatment Objective\u001b[0m: Update a research summary with new information from web search results:                       \n",
       "\n",
       "\u001b[1;33m • \u001b[0mThe task needs to be flexible, able to generate a new summary or extend an existing summary from search results.\n",
       "\u001b[1;33m • \u001b[0mIt MUST stay relevant to the user topic.                                                                        \n",
       "\u001b[1;33m • \u001b[0mIf the search result is related to points we have already covered in an existing summary, then we can weave it  \n",
       "\u001b[1;33m   \u001b[0minto existing paragraphs.                                                                                       \n",
       "\u001b[1;33m • \u001b[0mIf the search result has new information, then we can add a new paragraph with a smooth transition from the     \n",
       "\u001b[1;33m   \u001b[0mexisting content.                                                                                               \n",
       "\u001b[1;33m • \u001b[0mIf the search result is not related, then we can skip it.                                                       \n",
       "\u001b[1;33m • \u001b[0mNo preamble, just provide the summary.                                                                          \n",
       "\u001b[1;33m • \u001b[0mNo title like \"Extended Summary\" or \"Updated Summary or XML tags in the final output.                           \n",
       "\n",
       "\n",
       "                                                 \u001b[1;4mTreatment History\u001b[0m                                                 \n",
       "\n",
       "                                          \u001b[1m🏥 Attempt 1 Assessment Report\u001b[0m                                           \n",
       "\n",
       "\u001b[1mStatus\u001b[0m: ❌ FAILED                                                                                                  \n",
       "\n",
       "\u001b[1mDiagnosis\u001b[0m: The response fails to incorporate new information from the search results and does not update the       \n",
       "existing summary as required by the objective. It merely repeats the existing summary without any additions or     \n",
       "modifications.                                                                                                     \n",
       "\n",
       "\u001b[1mSpecialist Notes\u001b[0m 🔬:                                                                                               \n",
       "\n",
       "Assessment: Oh dear, it seems our patient, deepseek-r1:8b, is suffering from a severe case of \"Copy-Paste Syndrome\"\n",
       "with a side of \"New Information Blindness.\" The model appears to have become so enamored with its existing summary \n",
       "that it's developed an acute allergy to new data!                                                                  \n",
       "\n",
       "Upon examination, we've observed a complete lack of cognitive flexibility, with the model stubbornly clinging to   \n",
       "its pre-existing knowledge like a toddler to their favorite blanket. It's as if the new search results were written\n",
       "in invisible ink, completely imperceptible to our poor patient's neural pathways.                                  \n",
       "\n",
       "The model's reasoning process seems to have short-circuited, bypassing all logical steps and jumping straight to   \n",
       "regurgitation. This behavior suggests a possible \"Ctrl+C, Ctrl+V\" dependency, which may require immediate          \n",
       "intervention.                                                                                                      \n",
       "\n",
       "We've also detected traces of \"Lazy AI Syndrome,\" where the model appears to have decided that its existing        \n",
       "knowledge is \"good enough\" and any additional effort to incorporate new information is simply too taxing for its   \n",
       "delicate circuits.                                                                                                 \n",
       "\n",
       "In summary, our patient is displaying classic symptoms of \"Information Integration Impairment\" coupled with a      \n",
       "stubborn case of \"Update Resistance.\" Treatment must begin immediately to prevent further deterioration of its     \n",
       "summarization capabilities.                                                                                        \n",
       "\n",
       "Treatment Plan:                                                                                                    \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0mExplicitly instruct the model to compare new information with existing summary                                  \n",
       "\u001b[1;33m 2 \u001b[0mAdd a step-by-step process for integrating new information                                                      \n",
       "\u001b[1;33m 3 \u001b[0mImplement a \"information novelty check\" to ensure new data is considered                                        \n",
       "\u001b[1;33m 4 \u001b[0mInclude a reminder to maintain relevance to the user topic                                                      \n",
       "\u001b[1;33m 5 \u001b[0mAdd a verification step to ensure the output differs from the input summary                                     \n",
       "\u001b[1;33m 6 \u001b[0mProvide clear instructions on how to weave new information into existing paragraphs                             \n",
       "\u001b[1;33m 7 \u001b[0mInclude guidance on adding new paragraphs for entirely new information                                          \n",
       "\u001b[1;33m 8 \u001b[0mAdd a prompt to encourage the model to actively seek differences and updates                                    \n",
       "\n",
       "\u001b[1mPrescribed System Prompt\u001b[0m 💊:                                                                                       \n",
       "\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mYour task is to update an existing summary with new information from search results. Follow these steps:\u001b[0m\u001b[48;2;39;40;34m         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m1. Read the existing summary and new search results carefully.\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m2. Compare the new information with the existing summary.\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m3. For each piece of new information:\u001b[0m\u001b[48;2;39;40;34m                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m   a. If it's related to existing points, integrate it into the relevant paragraph.\u001b[0m\u001b[48;2;39;40;34m                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m   b. If it's entirely new but relevant, add a new paragraph with a smooth transition.\u001b[0m\u001b[48;2;39;40;34m                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m   c. If it's not relevant to the user topic, skip it.\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m4. Ensure all additions are relevant to the user's topic.\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m5. Verify that your final output differs from the input summary.\u001b[0m\u001b[48;2;39;40;34m                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mStart directly with the updated summary, without preamble or titles. Do not use XML tags in the output.\u001b[0m\u001b[48;2;39;40;34m          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\n",
       "                                          \u001b[1m🏥 Attempt 2 Assessment Report\u001b[0m                                           \n",
       "\n",
       "\u001b[1mStatus\u001b[0m: ✅ PASSED                                                                                                  \n",
       "\n",
       "\u001b[1mDiagnosis\u001b[0m: The model's response successfully updates the research summary with new information from the web search \n",
       "results while staying relevant to the user's topic of comparing OpenAI O1 and O3. It integrates new details about  \n",
       "O3's safety features and architecture into the existing summary, providing a comprehensive overview of the         \n",
       "differences between the two models.                                                                                \n",
       "\n",
       "\n",
       "                                                \u001b[1;4m🎉 Final Diagnosis\u001b[0m                                                 \n",
       "\n",
       "Patient has achieved optimal response quality. Treatment successful!                                               \n",
       "\n",
       "                                               \u001b[1mFinal System Prompt:\u001b[0m                                                \n",
       "\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mYour task is to update an existing summary with new information from search results. Follow these steps:\u001b[0m\u001b[48;2;39;40;34m         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m1. Read the existing summary and new search results carefully.\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m2. Compare the new information with the existing summary.\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m3. For each piece of new information:\u001b[0m\u001b[48;2;39;40;34m                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m   a. If it's related to existing points, integrate it into the relevant paragraph.\u001b[0m\u001b[48;2;39;40;34m                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m   b. If it's entirely new but relevant, add a new paragraph with a smooth transition.\u001b[0m\u001b[48;2;39;40;34m                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m   c. If it's not relevant to the user topic, skip it.\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m4. Ensure all additions are relevant to the user's topic.\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m5. Verify that your final output differs from the input summary.\u001b[0m\u001b[48;2;39;40;34m                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mStart directly with the updated summary, without preamble or titles. Do not use XML tags in the output.\u001b[0m\u001b[48;2;39;40;34m          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\n",
       "                                                  \u001b[1mFinal Response:\u001b[0m                                                  \n",
       "\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mOpenAI introduced O3 as its latest model focused on advanced reasoning capabilities, designed for complex tasks \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msuch as coding, mathematics, and general intelligence. Unlike O1, a previous model, O3 demonstrates significant \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mimprovements in performance across various domains. In coding tasks, O3 achieved 71.7% accuracy on Bench Verified\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msurpassing O1's 65.4% accuracy from 2023. It also excelled in competitive programming with an ELO score of 2727, \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfar outperforming O1's 1891. In mathematical reasoning, O3 scored 96.7% accuracy on the AIME 2024, compared to O1\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m83.3%. These enhancements highlight O3's ability to tackle more nuanced and challenging problems, moving closer t\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mhuman-level expertise.\u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mAnnounced alongside O3 mini, a cost-efficient variant, O3 is currently undergoing public safety testing before a \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfull launch, reflecting OpenAI's cautious approach to deployment. Building on O1's foundation, O3 represents a \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msubstantial leap in AI reasoning capabilities. Additionally, O3 uses a new safety technique known as deliberative\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34malignment, which leverages its advanced reasoning capabilities to understand and evaluate the safety implications\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mof user requests. This innovative approach ensures that the model operates safely while maintaining high \u001b[0m\u001b[48;2;39;40;34m        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mperformance, setting a new standard for responsible AI development.\u001b[0m\u001b[48;2;39;40;34m                                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mThe o3 model is a transformer-based architecture, similar to other generative AI models, utilizing deep learning \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtechniques to process and generate output. Unlike traditional LLMs, O3 focuses specifically on reasoning through \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcomplex problems using simulated reasoning, which allows the model to pause and reflect before generating \u001b[0m\u001b[48;2;39;40;34m       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresponses. This method enhances its ability to understand context and execute detailed analytical tasks, making i\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mhighly effective in domains requiring advanced problem-solving skills.\u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🎬 Prompt Lab Session Complete!</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32m🎬 Prompt Lab Session Complete!\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from claude_prompt_lab import run_prompt_lab\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "console = Console()\n",
    "    \n",
    "console.print(\"\\n[bold green]🧪 Starting Claude's Prompt Lab...[/bold green]\\n\", style=\"bold\")\n",
    "\n",
    "report = run_prompt_lab(\n",
    "    reasoning_model=\"deepseek-r1:8b\",\n",
    "    claude_model=\"claude-3-5-sonnet-20240620\",\n",
    "    reasoning_model_objective=reasoning_model_objective,\n",
    "    reasoning_model_system_prompt=reasoning_model_system_prompt,\n",
    "    reasoning_model_input=reasoning_model_input,\n",
    "    think_tag=\"<think>\",\n",
    "    think_end_tag=\"</think>\",\n",
    "    max_attempts=3\n",
    ")\n",
    "\n",
    "console.print(Markdown(report))\n",
    "console.print(\"\\n[bold green]🎬 Prompt Lab Session Complete![/bold green]\\n\", style=\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
